# 研究发现: 数据同步系统

## 当前数据结构分析

### 已有的时间字段
- `starred_at` - 用户 star 的时间 ✅
- `pushed_at` - 仓库最后提交时间 ✅
- `created_at` - 本地记录创建时间 ✅
- `updated_at` - 本地记录更新时间 ✅
- `indexed_at` - 索引时间 ✅

### GitHub API 时效性
- REST API: 支持 `since` 参数获取增量数据
- GraphQL: 支持 `starred_at` 排序和过滤
- Rate Limit: 认证 5000次/小时，未认证 60次/小时

## 同步场景分析

### 场景 1: 用户 star 新仓库
- **检测**: GitHub 有，本地没有
- **操作**: INSERT 新仓库记录
- **LLM**: 可选分析

### 场景 2: 仓库有更新
- **检测**: `pushed_at` 变化，`stargazer_count` 变化
- **操作**: UPDATE 元数据
- **LLM**: 不自动重新分析

### 场景 3: 用户取消 star
- **检测**: 本地有，GitHub 没有
- **操作**: `is_deleted = 1`
- **数据**: 保留笔记和标签

### 场景 4: 重新 star 已删除的仓库
- **检测**: GitHub 有，本地存在但 `is_deleted = 1`
- **操作**: `is_deleted = 0`，更新元数据
- **数据**: 恢复原有笔记和标签

## 技术选型

### 定时任务
- **APScheduler**: Python 标准选择，支持 cron 表达式
- **替代方案**: Celery（过重）、系统 cron（不跨平台）

### 增量检测
- **基于时间**: 使用 `last_synced_at` 和 GitHub API 的 `since`
- **GitHub 限制**: REST API 的 star 列表按时间倒序，需要获取全部后对比

## 数据一致性

### 并发同步
- 使用事务保证批量操作的原子性
- 同步锁防止重复同步

### 错误恢复
- 记录同步历史，支持断点续传
- 失败仓库不阻塞整体同步

## 性能考虑

### 全量同步开销
- 100 个仓库 ~ 100 次 API 调用
- 使用 token 支持 5000次/小时
- 建议每周做一次全量校验

### 增量同步效率
- 每日新增通常 < 10 个
- 大部分时间只检测更新，不获取 README
